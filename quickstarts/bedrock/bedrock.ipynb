{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Bedrock Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import urllib3\n",
    "\n",
    "from payi.lib.helpers import payi_aws_bedrock_url\n",
    "\n",
    "# Read the API KEYs from the environment, replace the default values (the second argument) with your own keys if needed\n",
    "payi_api_key = os.getenv(\"PAYI_API_KEY\", \"YOUR_PAYI_API_KEY\")\n",
    "\n",
    "payi_aws_bedrock_url_path = payi_aws_bedrock_url()\n",
    "\n",
    "def handle_payi_parameters(params, context, **kwargs):\n",
    "    context[\"extra_headers\"] = params.pop(\"extra_headers\", {})\n",
    "\n",
    "def redirect_to_payi(request, event_name, **kwargs):\n",
    "    if not event_name.startswith('request-created.bedrock-runtime'):\n",
    "        return\n",
    "    \n",
    "    parsed_url = urllib3.util.parse_url(request.url)\n",
    "    route_path = parsed_url.path\n",
    "    request.url = f\"{payi_aws_bedrock_url_path}{route_path}\"\n",
    "\n",
    "    request.headers['xProxy-api-key'] = payi_api_key\n",
    "    request.headers['xProxy-Provider-BaseUri'] = parsed_url.scheme + \"://\" + parsed_url.host\n",
    "    extra_headers = request.context.get('extra_headers', {})\n",
    "    for key, value in extra_headers.items():\n",
    "        request.headers[key] = value\n",
    "\n",
    "\n",
    "def register_bedrock_client_callbacks(client, model):\n",
    "    # Pass a unqiue_id to avoid registering the same callback multiple times in case this cell executed more than once\n",
    "\n",
    "    # Process the extra_headers parameter passed to the bedrock runtime call before the AWS client validates the input parameters\n",
    "    client.meta.events.register(f'provide-client-params.bedrock-runtime.{model}', handle_payi_parameters, unique_id=handle_payi_parameters)\n",
    "\n",
    "    # Redirect the request to the Pay-i endpoint after the request has been signed. \n",
    "    client.meta.events.register_last('request-created', redirect_to_payi, unique_id=redirect_to_payi)\n",
    "    \n",
    "# Substitute the region for your regional deployment\n",
    "region_name = \"us-west-2\"\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    'bedrock-runtime',\n",
    "    region_name=region_name,\n",
    "    )\n",
    "\n",
    "# Register client callbacks to handle the Pay-i extra_headers parameter in the inference calls and redirect the request to the Pay-i endpoint\n",
    "register_bedrock_client_callbacks(bedrock, 'InvokeModel')\n",
    "register_bedrock_client_callbacks(bedrock, 'InvokeModelWithResponseStream')\n",
    "register_bedrock_client_callbacks(bedrock, 'Converse')\n",
    "register_bedrock_client_callbacks(bedrock, 'ConverseStream')\n",
    "\n",
    "request_dict = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"this is a test\"}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert the request to JSON\n",
    "request_body = json.dumps(request_dict)\n",
    "model_id = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "# Invoke the model with the request.\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    )\n",
    "\n",
    "# Decode the response body.\n",
    "response = invoke_response[\"body\"].read()\n",
    "\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(\"xproxy_result:\")\n",
    "print(json.dumps(xproxy_result, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke stream invocation with pay-i as the proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = bedrock.invoke_model_with_response_stream(\n",
    "    body=request_body,\n",
    "    modelId=model_id, \n",
    ")\n",
    "\n",
    "message = \"\"\n",
    "input_tokens = None\n",
    "output_tokens = None\n",
    "invoke_id = None\n",
    "\n",
    "stream = response.get('body')\n",
    "\n",
    "for event in stream:\n",
    "    chunk = event.get('chunk')\n",
    "    if not chunk:\n",
    "        continue\n",
    "\n",
    "    decode = json.loads(chunk.get('bytes').decode())\n",
    "\n",
    "    match decode['type']:\n",
    "        case \"message_start\":\n",
    "            input_tokens = decode['message']['usage']['input_tokens']\n",
    "            invoke_id = decode['message']['id']\n",
    "        case \"content_block_start\":\n",
    "            message += decode['content_block']['text']\n",
    "        case \"content_block_delta\":\n",
    "            message += decode['delta']['text']\n",
    "        case \"message_delta\":\n",
    "            output_tokens = decode['usage']['output_tokens']\n",
    "        case \"content_block_stop\" | \"message_stop\":\n",
    "            ...\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converse stream invocation with pay-i as the proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converse_request_dict=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"this is a test\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "converse_request_inference_config={\n",
    "    \"temperature\": 0.5,\n",
    "    \"maxTokens\": 512,\n",
    "}\n",
    "\n",
    "converse_response = bedrock.converse_stream(\n",
    "    modelId=model_id,\n",
    "    messages=converse_request_dict,\n",
    "    inferenceConfig=converse_request_inference_config\n",
    ")\n",
    "\n",
    "stream = converse_response['stream']\n",
    "\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        # print(f'{json.dumps(event, indent=2)}')\n",
    "\n",
    "        # decode = json.loads(event)\n",
    "        \n",
    "        if 'contentBlockDelta' in event:\n",
    "            message += event['contentBlockDelta']['delta']['text']\n",
    "        elif 'metadata' in event:\n",
    "            input_tokens = event['metadata']['usage']['inputTokens']\n",
    "            output_tokens = event['metadata']['usage']['outputTokens']\n",
    "\n",
    "print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the payi client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from payi import Payi\n",
    "\n",
    "payi_client = Payi(\n",
    "    api_key=payi_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Pay-i SDK to generate the headers to send a request with request tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from payi.lib.helpers import create_headers\n",
    "\n",
    "# The AWS client will only allow the extra_headers parameter if the event callbacks above are registered\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(request_tags=[\"x\", \"y\"])\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(\"xproxy_result:\")\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a limit and make a request with that limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a limit\n",
    "limit_response = payi_client.limits.create(\n",
    "    # As long as the limit configuration remains the same across creates, the same limit name can be used repeatedly\n",
    "    limit_name='Bedrock quickstart allow limit',\n",
    "    max=12.50, #$12.50 USD\n",
    "    limit_type=\"Allow\",\n",
    "    limit_tags=[\"example_limit\"]\n",
    ")\n",
    "\n",
    "limit_name = limit_response.limit.limit_name\n",
    "limit_id = limit_response.limit.limit_id\n",
    "\n",
    "print(\"Limit Created\")\n",
    "print(f\"Limit Name: {limit_name}\")\n",
    "print(f\"Limit ID: {limit_id}\")\n",
    "\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(\n",
    "        request_tags=[\"x\", \"y\"],\n",
    "        limit_ids=[limit_id]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See limit status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.limits.retrieve(limit_id=limit_id)\n",
    "print(f\"Limit Name: {invoke_response.limit.limit_name}\")\n",
    "print(f\"Limit ID: {invoke_response.limit.limit_id}\")\n",
    "print(f\"Limit Creation Timestamp: {invoke_response.limit.limit_creation_timestamp}\")\n",
    "print(f\"Limit Tags: {invoke_response.limit.limit_tags}\")\n",
    "print(f\"Limit Input Base Cost: {invoke_response.limit.totals.cost.input.base}\")\n",
    "print(f\"Limit Output Base Cost: {invoke_response.limit.totals.cost.output.base}\")\n",
    "print(f\"Limit Total Base Cost: {invoke_response.limit.totals.cost.output.base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an ingest call with pre-computed token values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.ingest.units(\n",
    "    category=\"system.aws.bedrock\",\n",
    "    resource=model_id,\n",
    "    units={ \"text\": { \"input\": 50, \"output\": 100 } },\n",
    "    limit_ids=[limit_id],\n",
    "    request_tags=[\"a\", \"b\"]\n",
    ")\n",
    "\n",
    "print(f\"Ingest request ID: {invoke_response.request_id}\")\n",
    "print(f\"Input Base Cost: {invoke_response.xproxy_result.cost.input.base}\")\n",
    "print(f\"Output Base Cost: {invoke_response.xproxy_result.cost.output.base}\")\n",
    "print(f\"Total Base Cost: {invoke_response.xproxy_result.cost.total.base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset a limit back to zero tracked cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.limits.reset(limit_id=limit_id)\n",
    "print(invoke_response.message)\n",
    "print(\"State prior to reset: \")\n",
    "print(f\"Limit Name: {invoke_response.limit_history.limit_name}\")\n",
    "print(f\"Limit ID: {invoke_response.limit_history.limit_id}\")\n",
    "print(f\"Limit Tags: {invoke_response.limit_history.limit_tags}\")\n",
    "print(f\"Limit Reset Timestamp: {invoke_response.limit_history.limit_reset_timestamp}\")\n",
    "print(f\"Limit Input Base Cost: {invoke_response.limit_history.totals.cost.input.base}\")\n",
    "print(f\"Limit Output Base Cost: {invoke_response.limit_history.totals.cost.output.base}\")\n",
    "print(f\"Limit Total Base Cost: {invoke_response.limit_history.totals.cost.total.base}\")\n",
    "\n",
    "print(\"\\nState after reset:\")\n",
    "invoke_response = payi_client.limits.retrieve(limit_id=limit_id)\n",
    "print(f\"Limit Name: {invoke_response.limit.limit_name}\")\n",
    "print(f\"Limit ID: {invoke_response.limit.limit_id}\")\n",
    "print(f\"Limit Creation Timestamp: {invoke_response.limit.limit_creation_timestamp}\")\n",
    "print(f\"Limit Tags: {invoke_response.limit.limit_tags}\")\n",
    "print(f\"Limit Input Base Cost: {invoke_response.limit.totals.cost}\")\n",
    "print(f\"Limit Output Base Cost: {invoke_response.limit.totals.cost.output.base}\")\n",
    "print(f\"Limit Total Base Cost: {invoke_response.limit.totals.cost.total.base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a small blocking limit that will prevent calls from happening that exceed the maximum, then capture the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_response = payi_client.limits.create(\n",
    "    #As long as the limit configuration remains the same across creates, the same limit name can be used repeatedly\n",
    "    limit_name='Bedrock quickstart block limit',\n",
    "    max=0.00000001, \n",
    "    limit_type=\"block\",\n",
    "    limit_tags=[\"limit_block_example\"]\n",
    ")\n",
    "block_limit = limit_response.limit.limit_id\n",
    "\n",
    "print(\"Limit Created\")\n",
    "print(f\"Limit Name: {limit_response.limit.limit_name}\")\n",
    "print(f\"Limit ID: {limit_response.limit.limit_id}\")\n",
    "\n",
    "try:\n",
    "    longer_request_1_dict = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"provide me a list of toys for children 5 and under\"}],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    longer_request_1_body =json.dumps(longer_request_1_dict)\n",
    "\n",
    "    invoke_response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=longer_request_1_body,\n",
    "        extra_headers=create_headers(\n",
    "            request_tags=[\"x\", \"y\"],\n",
    "            limit_ids=[block_limit]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    response = invoke_response[\"body\"].read()\n",
    "    response_json = json.loads(response)\n",
    "    print(json.dumps(response_json, indent=4))\n",
    "\n",
    "    longer_request_2_dict = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"tell me a short story about a toy\"}],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    longer_request_2_body =json.dumps(longer_request_2_dict)\n",
    "\n",
    "    invoke_response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=longer_request_2_body,\n",
    "        extra_headers=create_headers(\n",
    "            request_tags=[\"x\", \"y\"],\n",
    "            limit_ids=[block_limit]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # This will note execute as invoke_model call will raise an exception due to the blocking limit returning with a 4xx HTTP status code\n",
    "    response = invoke_response[\"body\"].read()\n",
    "    response_json = json.loads(response)\n",
    "    print(json.dumps(response_json, indent=4))\n",
    "\n",
    "except Exception as e:\n",
    "    print(json.dumps(e.response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an experience type and send a request with it. Pay-i will auto generate an experience id that can be specified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experience type\n",
    "exp_name=\"quickstart_experience\"\n",
    "exp_type_response = payi_client.experiences.types.create(\n",
    "    name=exp_name,\n",
    "    description=\"An example of an experience\"\n",
    ")\n",
    "\n",
    "# Make a request using the limit, request tags, and experience\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(\n",
    "        request_tags=[\"x\", \"y\"],\n",
    "        limit_ids=[limit_id],\n",
    "        experience_name=exp_name\n",
    "    )\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "experience_id = xproxy_result['experience_id']\n",
    "print(\"xproxy_result:\")\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request with a limit and user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request using the limit, request tags, and user id\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(\n",
    "        limit_ids=[limit_id],\n",
    "        # user id can be any string value\n",
    "        user_id=\"example_user_id\"\n",
    "    )\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List and then delete all limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.limits.list()\n",
    "for limit in invoke_response.items:\n",
    "    print(\"Deleting limit with id:\" + limit.limit_id)\n",
    "    payi_client.limits.delete(limit.limit_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
