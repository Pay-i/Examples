{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (1.36.15)\n",
      "Requirement already satisfied: payi in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (0.1.0a46)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.15 in ./.venv/lib/python3.13/site-packages (from boto3->-r requirements.txt (line 1)) (1.36.15)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./.venv/lib/python3.13/site-packages (from boto3->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in ./.venv/lib/python3.13/site-packages (from boto3->-r requirements.txt (line 1)) (0.11.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tiktoken>=0.8.0 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.17.2 in ./.venv/lib/python3.13/site-packages (from payi->-r requirements.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->payi->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.venv/lib/python3.13/site-packages (from botocore<1.37.0,>=1.36.15->boto3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in ./.venv/lib/python3.13/site-packages (from botocore<1.37.0,>=1.36.15->boto3->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->payi->-r requirements.txt (line 2)) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->payi->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->payi->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->payi->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->payi->-r requirements.txt (line 2)) (2.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken>=0.8.0->payi->-r requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.13/site-packages (from tiktoken>=0.8.0->payi->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.15->boto3->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken>=0.8.0->payi->-r requirements.txt (line 2)) (3.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Bedrock Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"msg_bdrk_01U82fQW1KfLpKMuL7DKyQAi\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Okay, this is a test. I'm ready to assist you with any questions or tasks you may have.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 11,\n",
      "        \"output_tokens\": 26\n",
      "    },\n",
      "    \"xproxy_result\": {\n",
      "        \"request_id\": \"1816171\",\n",
      "        \"resource_id\": \"75\",\n",
      "        \"cost\": {\n",
      "            \"currency\": \"usd\",\n",
      "            \"input\": {\n",
      "                \"base\": 2.75e-06\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"base\": 3.25e-05\n",
      "            },\n",
      "            \"total\": {\n",
      "                \"base\": 3.525e-05\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "xproxy_result:\n",
      "{\n",
      "    \"request_id\": \"1816171\",\n",
      "    \"resource_id\": \"75\",\n",
      "    \"cost\": {\n",
      "        \"currency\": \"usd\",\n",
      "        \"input\": {\n",
      "            \"base\": 2.75e-06\n",
      "        },\n",
      "        \"output\": {\n",
      "            \"base\": 3.25e-05\n",
      "        },\n",
      "        \"total\": {\n",
      "            \"base\": 3.525e-05\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import urllib3\n",
    "\n",
    "# Read the API KEYs from the environment, replace the default values (the second argument) with your own keys if needed\n",
    "payi_api_key = os.getenv(\"PAYI_API_KEY\", \"YOUR_PAYI_API_KEY\")\n",
    "\n",
    "payi_base_url = \"https://api.pay-i.com\"\n",
    "\n",
    "def handle_payi_parameters(params, context, **kwargs):\n",
    "    context[\"extra_headers\"] = params.pop(\"extra_headers\", {})\n",
    "\n",
    "def redirect_to_payi(request, event_name, **kwargs):\n",
    "    if not event_name.startswith('request-created.bedrock-runtime'):\n",
    "        return\n",
    "    \n",
    "    parsed_url = urllib3.util.parse_url(request.url)\n",
    "    route_path = parsed_url.path\n",
    "    request.url = f\"{payi_base_url}/api/v1/proxy/aws.bedrock{route_path}\"\n",
    "\n",
    "    request.headers['xProxy-api-key'] = payi_api_key\n",
    "    request.headers['xProxy-Provider-BaseUri'] = parsed_url.scheme + \"://\" + parsed_url.host\n",
    "    extra_headers = request.context.get('extra_headers', {})\n",
    "    for key, value in extra_headers.items():\n",
    "        request.headers[key] = value\n",
    "\n",
    "\n",
    "def register_bedrock_client_callbacks(client, model):\n",
    "    # Pass a unqiue_id to avoid registering the same callback multiple times in case this cell executed more than once\n",
    "\n",
    "    # Process the extra_headers parameter passed to the bedrock runtime call before the AWS client validates the input parameters\n",
    "    client.meta.events.register(f'provide-client-params.bedrock-runtime.{model}', handle_payi_parameters, unique_id=handle_payi_parameters)\n",
    "\n",
    "    # Redirect the request to the Pay-i endpoint after the request has been signed. \n",
    "    client.meta.events.register_last(f'request-created', redirect_to_payi, unique_id=redirect_to_payi)\n",
    "    \n",
    "# Substitute the region for your regional deployment\n",
    "region_name = \"us-west-2\"\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    'bedrock-runtime',\n",
    "    region_name=region_name,\n",
    "    )\n",
    "\n",
    "# Register client callbacks to handle the Pay-i extra_headers parameter in the inference calls and redirect the request to the Pay-i endpoint\n",
    "register_bedrock_client_callbacks(bedrock, 'InvokeModel')\n",
    "register_bedrock_client_callbacks(bedrock, 'InvokeModelWithResponseStream')\n",
    "register_bedrock_client_callbacks(bedrock, 'Converse')\n",
    "register_bedrock_client_callbacks(bedrock, 'ConverseStream')\n",
    "\n",
    "request_dict = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"this is a test\"}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert the request to JSON\n",
    "request_body = json.dumps(request_dict)\n",
    "model_id = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "# Invoke the model with the request.\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    )\n",
    "\n",
    "# Decode the response body.\n",
    "response = invoke_response[\"body\"].read()\n",
    "\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(\"xproxy_result:\")\n",
    "print(json.dumps(xproxy_result, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke stream invocation with pay-i as the proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, this is a test. I'm ready to assist you with any questions or tasks you may have.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = bedrock.invoke_model_with_response_stream(\n",
    "    body=request_body,\n",
    "    modelId=model_id, \n",
    ")\n",
    "\n",
    "message = \"\"\n",
    "input_tokens = None\n",
    "output_tokens = None\n",
    "invoke_id = None\n",
    "\n",
    "stream = response.get('body')\n",
    "\n",
    "for event in stream:\n",
    "    chunk = event.get('chunk')\n",
    "    if not chunk:\n",
    "        continue\n",
    "\n",
    "    decode = json.loads(chunk.get('bytes').decode())\n",
    "\n",
    "    match decode['type']:\n",
    "        case \"message_start\":\n",
    "            input_tokens = decode['message']['usage']['input_tokens']\n",
    "            invoke_id = decode['message']['id']\n",
    "        case \"content_block_start\":\n",
    "            message += decode['content_block']['text']\n",
    "        case \"content_block_delta\":\n",
    "            message += decode['delta']['text']\n",
    "        case \"message_delta\":\n",
    "            output_tokens = decode['usage']['output_tokens']\n",
    "        case \"content_block_stop\" | \"message_stop\":\n",
    "            ...\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converse stream invocation with pay-i as the proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, this is a test. I'm ready to assist you with any questions or tasks you may have.Okay, this is a test. I'm ready to assist you with whatever you need.\n"
     ]
    }
   ],
   "source": [
    "converse_request_dict=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"this is a test\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "converse_request_inference_config={\n",
    "    \"temperature\": 0.5,\n",
    "    \"maxTokens\": 512,\n",
    "}\n",
    "\n",
    "converse_response = bedrock.converse_stream(\n",
    "    modelId=model_id,\n",
    "    messages=converse_request_dict,\n",
    "    inferenceConfig=converse_request_inference_config\n",
    ")\n",
    "\n",
    "stream = converse_response['stream']\n",
    "\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        # print(f'{json.dumps(event, indent=2)}')\n",
    "\n",
    "        # decode = json.loads(event)\n",
    "        \n",
    "        if 'contentBlockDelta' in event:\n",
    "            message += event['contentBlockDelta']['delta']['text']\n",
    "        elif 'metadata' in event:\n",
    "            input_tokens = event['metadata']['usage']['inputTokens']\n",
    "            output_tokens = event['metadata']['usage']['outputTokens']\n",
    "\n",
    "print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the payi client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from payi import Payi\n",
    "\n",
    "payi_client = Payi(\n",
    "    api_key=payi_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Pay-i SDK to generate the headers to send a request with request tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"msg_bdrk_01M9jKDZvccNihb12j5mWaji\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Okay, this is a test response from me.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 11,\n",
      "        \"output_tokens\": 14\n",
      "    },\n",
      "    \"xproxy_result\": {\n",
      "        \"request_id\": \"1816172\",\n",
      "        \"request_tags\": [\n",
      "            \"x\",\n",
      "            \"y\"\n",
      "        ],\n",
      "        \"resource_id\": \"75\",\n",
      "        \"cost\": {\n",
      "            \"currency\": \"usd\",\n",
      "            \"input\": {\n",
      "                \"base\": 2.75e-06\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"base\": 1.75e-05\n",
      "            },\n",
      "            \"total\": {\n",
      "                \"base\": 2.025e-05\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "xproxy_result:\n",
      "{\n",
      "    \"request_id\": \"1816172\",\n",
      "    \"request_tags\": [\n",
      "        \"x\",\n",
      "        \"y\"\n",
      "    ],\n",
      "    \"resource_id\": \"75\",\n",
      "    \"cost\": {\n",
      "        \"currency\": \"usd\",\n",
      "        \"input\": {\n",
      "            \"base\": 2.75e-06\n",
      "        },\n",
      "        \"output\": {\n",
      "            \"base\": 1.75e-05\n",
      "        },\n",
      "        \"total\": {\n",
      "            \"base\": 2.025e-05\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from payi.lib.helpers import create_headers\n",
    "\n",
    "# The AWS client will only allow the extra_headers parameter if the event callbacks above are registered\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(request_tags=[\"x\", \"y\"])\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(\"xproxy_result:\")\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a limit and make a request with that limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a limit\n",
    "limit_response = payi_client.limits.create(\n",
    "    # As long as the limit configuration remains the same across creates, the same limit name can be used repeatedly\n",
    "    limit_name='Bedrock quickstart allow limit',\n",
    "    max=12.50, #$12.50 USD\n",
    "    limit_type=\"Allow\",\n",
    "    limit_tags=[\"example_limit\"]\n",
    ")\n",
    "\n",
    "limit_name = limit_response.limit.limit_name\n",
    "limit_id = limit_response.limit.limit_id\n",
    "\n",
    "print(\"Limit Created\")\n",
    "print(f\"Limit Name: {limit_name}\")\n",
    "print(f\"Limit ID: {limit_id}\")\n",
    "\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(\n",
    "        request_tags=[\"x\", \"y\"],\n",
    "        limit_ids=[limit_id]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See limit status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.limits.retrieve(limit_id=limit_id)\n",
    "print(f\"Limit Name: {invoke_response.limit.limit_name}\")\n",
    "print(f\"Limit ID: {invoke_response.limit.limit_id}\")\n",
    "print(f\"Limit Creation Timestamp: {invoke_response.limit.limit_creation_timestamp}\")\n",
    "print(f\"Limit Tags: {invoke_response.limit.limit_tags}\")\n",
    "print(f\"Limit Input Base Cost: {invoke_response.limit.totals.cost.input.base}\")\n",
    "print(f\"Limit Output Base Cost: {invoke_response.limit.totals.cost.output.base}\")\n",
    "print(f\"Limit Total Base Cost: {invoke_response.limit.totals.cost.output.base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an ingest call with pre-computed token values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.ingest.units(\n",
    "    category=\"system.aws.bedrock\",\n",
    "    resource=model_id,\n",
    "    units={ \"text\": { \"input\": 50, \"output\": 100 } },\n",
    "    limit_ids=[limit_id],\n",
    "    request_tags=[\"a\", \"b\"]\n",
    ")\n",
    "\n",
    "print(f\"Ingest request ID: {invoke_response.request_id}\")\n",
    "print(f\"Input Base Cost: {invoke_response.xproxy_result.cost.input.base}\")\n",
    "print(f\"Output Base Cost: {invoke_response.xproxy_result.cost.output.base}\")\n",
    "print(f\"Total Base Cost: {invoke_response.xproxy_result.cost.total.base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset a limit back to zero tracked cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.limits.reset(limit_id=limit_id)\n",
    "print(invoke_response.message)\n",
    "print(\"State prior to reset: \")\n",
    "print(f\"Limit Name: {invoke_response.limit_history.limit_name}\")\n",
    "print(f\"Limit ID: {invoke_response.limit_history.limit_id}\")\n",
    "print(f\"Limit Tags: {invoke_response.limit_history.limit_tags}\")\n",
    "print(f\"Limit Reset Timestamp: {invoke_response.limit_history.limit_reset_timestamp}\")\n",
    "print(f\"Limit Input Base Cost: {invoke_response.limit_history.totals.cost.input.base}\")\n",
    "print(f\"Limit Output Base Cost: {invoke_response.limit_history.totals.cost.output.base}\")\n",
    "print(f\"Limit Total Base Cost: {invoke_response.limit_history.totals.cost.total.base}\")\n",
    "\n",
    "print(\"\\nState after reset:\")\n",
    "invoke_response = payi_client.limits.retrieve(limit_id=limit_id)\n",
    "print(f\"Limit Name: {invoke_response.limit.limit_name}\")\n",
    "print(f\"Limit ID: {invoke_response.limit.limit_id}\")\n",
    "print(f\"Limit Creation Timestamp: {invoke_response.limit.limit_creation_timestamp}\")\n",
    "print(f\"Limit Tags: {invoke_response.limit.limit_tags}\")\n",
    "print(f\"Limit Input Base Cost: {invoke_response.limit.totals.cost}\")\n",
    "print(f\"Limit Output Base Cost: {invoke_response.limit.totals.cost.output.base}\")\n",
    "print(f\"Limit Total Base Cost: {invoke_response.limit.totals.cost.total.base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a small blocking limit that will prevent calls from happening that exceed the maximum, then capture the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_response = payi_client.limits.create(\n",
    "    #As long as the limit configuration remains the same across creates, the same limit name can be used repeatedly\n",
    "    limit_name='Bedrock quickstart block limit',\n",
    "    max=0.00000001, \n",
    "    limit_type=\"block\",\n",
    "    limit_tags=[\"limit_block_example\"]\n",
    ")\n",
    "block_limit = limit_response.limit.limit_id\n",
    "\n",
    "print(\"Limit Created\")\n",
    "print(f\"Limit Name: {limit_response.limit.limit_name}\")\n",
    "print(f\"Limit ID: {limit_response.limit.limit_id}\")\n",
    "\n",
    "try:\n",
    "    longer_request_1_dict = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"provide me a list of toys for children 5 and under\"}],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    longer_request_1_body =json.dumps(longer_request_1_dict)\n",
    "\n",
    "    invoke_response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=longer_request_1_body,\n",
    "        extra_headers=create_headers(\n",
    "            request_tags=[\"x\", \"y\"],\n",
    "            limit_ids=[block_limit]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    response = invoke_response[\"body\"].read()\n",
    "    response_json = json.loads(response)\n",
    "    print(json.dumps(response_json, indent=4))\n",
    "\n",
    "    longer_request_2_dict = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"tell me a short story about a toy\"}],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    longer_request_2_body =json.dumps(longer_request_2_dict)\n",
    "\n",
    "    invoke_response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=longer_request_2_body,\n",
    "        extra_headers=create_headers(\n",
    "            request_tags=[\"x\", \"y\"],\n",
    "            limit_ids=[block_limit]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # This will note execute as invoke_model call will raise an exception due to the blocking limit returning with a 4xx HTTP status code\n",
    "    response = invoke_response[\"body\"].read()\n",
    "    response_json = json.loads(response)\n",
    "    print(json.dumps(response_json, indent=4))\n",
    "\n",
    "except Exception as e:\n",
    "    print(json.dumps(e.response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an experience type and send a request with it. Pay-i will auto generate an experience id that can be specified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experience type\n",
    "exp_name=\"quickstart_experience\"\n",
    "exp_type_response = payi_client.experiences.types.create(\n",
    "    name=exp_name,\n",
    "    description=\"An example of an experience\"\n",
    ")\n",
    "\n",
    "# Make a request using the limit, request tags, and experience\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(\n",
    "        request_tags=[\"x\", \"y\"],\n",
    "        limit_ids=[limit_id],\n",
    "        experience_name=exp_name\n",
    "    )\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "experience_id = xproxy_result['experience_id']\n",
    "print(\"xproxy_result:\")\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request with a limit and user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request using the limit, request tags, and user id\n",
    "invoke_response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    extra_headers=create_headers(\n",
    "        limit_ids=[limit_id],\n",
    "        # user id can be any string value\n",
    "        user_id=\"example_user_id\"\n",
    "    )\n",
    ")\n",
    "\n",
    "response = invoke_response[\"body\"].read()\n",
    "response_json = json.loads(response)\n",
    "print(json.dumps(response_json, indent=4))\n",
    "\n",
    "xproxy_result = response_json['xproxy_result']\n",
    "print(json.dumps(xproxy_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List and then delete all limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = payi_client.limits.list()\n",
    "for limit in invoke_response.items:\n",
    "    print(\"Deleting limit with id:\" + limit.limit_id)\n",
    "    payi_client.limits.delete(limit.limit_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
